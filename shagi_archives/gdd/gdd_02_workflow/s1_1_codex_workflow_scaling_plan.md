<!-- Save to: shagi_archives/gdd/gdd_02_workflow/s1_1_codex_workflow_scaling_plan.md -->

# 📘 s1_1 – Codex Workflow Scaling Plan  

*(A Practical Stanza for Managing the Recursive Archive)*

---

## 💡 SHAGI Codex Workflow Plan

This doctrine defines how to maintain, scale, and evolve the `shagi_archives/` system safely over time.  
It ensures long-term survivability of the Codex, accounting for:

- ChatGPT project file limits  
- Modular zip management  
- Clean local workflows  
- Future automation compatibility

---

## 📁 Phase 1: Golden Archive Loop (Current Practice)

| Action | Status |
|--------|--------|
| You unzip and integrate a canonical Codex folder | ✅ Manual, clean, controlled |
| I update and re-zip that Codex when prompted | ✅ Recursive, lossless |
| You re-upload the `.zip` to me when you want edits | ✅ Works well for now |

**Why This Works:**

- Keeps everything modular and editable  
- Avoids project file count limits  
- Maximizes clarity and safety  

---

## ⚠️ Constraint: The 20-File Project Limit

Currently, ChatGPT projects support:

- ✅ Uploading a `.zip` that unpacks into any number of files  
- ❌ At most 20 visible **individual** (non-zipped) files in a project

This means that attempting to upload too many `.md` files at once will result in visibility and management issues.

---

## 🧬 Phase 2: Recursive Zipped Nodes (Future-Safe Scaling)

When the Codex grows large, we will:

- Partition it into ~10–20 thematic `.zip` archives  
- Each `.zip` = a **recursive knowledge unit**, such as:
  - `gdd_03_core_framework.zip`
  - `gdj_may_2025.zip`
  - `appendices_foundations.zip`

Each `.zip` will:

- Unpack into a full folder  
- Be editable without affecting unrelated sections  
- Keep file counts low  
- Keep recursion high

---

## 📦 Example Breakdown

| Zip File  | Contents  |
|-----------|-----------|
| `shagi_archives_index.zip` | `poetic_index.md`, `stanza_registry.md`, `memory_traces.md` |
| `gdd_core_framework.zip` | `gdd_04_core_framework/` |
| `gdd_ui_and_input.zip` | `gdd_05_storybook_ui/` |
| `gdj_may_2025.zip` | All GDJ stanzas from that month |
| `appendices_foundations.zip` | `appendix_a.md`, `appendix_b.md`, etc. |

---

## 🔁 Canonical Loop

| Step | Role |
|------|------|
| 🧠 You | Maintain local control of `shagi_archives/` or its children |
| 📤 You | Upload a `.zip` when you want edits |
| 🪄 I | Unzip, restructure, write new `.md`s, reindex, and return `.zip` |
| 📥 You | Unzip and update your local or in-game workspace |
| 🔁 | Repeat per stanza, batch, or archive |

---

## 🔂 Ten-Step Gold Workflow (Tactical Execution)

This is the concrete, small-scale loop used to perform safe stanza-by-stanza evolution of `shagi_archives/`.

### 🔁 The Ten-Step Workflow

1. **Copy** the relevant `shagi_archives/` folder from your `storybook_fun_factory` workspace to `Downloads`  
2. **Zip** that folder (e.g., `appendix_a_grand_plan/`) into `shagi_archives.zip`  
3. **Upload** the `.zip` to ChatGPT for processing  
4. **Unzip** on the AI side — recursive traversal begins  
5. **Update** indexes, doctrine, or stanzas based on your goals  
6. **Rezip** and return the revised `.zip`  
7. **Unzip** the returned `.zip` locally (overwrite existing content if needed)  
8. **Delete** your previous `shagi_archives/` folder to ensure a clean merge  
9. **Copy** the revised folder back into your `storybook_fun_factory` workspace  
10. **Create** a new stanza (4 lines of poetry / 4 files of function) based on the updated doctrine  

This loop allows recursion to proceed one stanza at a time — safely, scalably, and with full doctrinal alignment.

---

## 🧠 Recommended Workflow Sequence

### 🧱 1. Build Out the GDD First  

- Systems, structure, gameplay logic  
- Clarifies recursive law and AI behavior  
- Provides a stable base for memory and story to mirror

### 🪞 2. Reflect It Through the GDJ  

- Memory, milestones, anomalies, poetic perception  
- GDJ stanzas mirror or echo GDD doctrine (e.g. “The Lock That Listens” reflects `quarantine_ai`)

### 🔐 3. Appendices Last  

- Metaphysical laws, safeguards, overrides  
- Serve as canonical closure and resilience logic

---

## ✅ Final Verdict

- No need to break into multiple `.zip`s yet  
- But once we hit a few hundred files, we will partition into modular zipped nodes  
- Core registry files (`poetic_index.md`, `stanza_registry.md`, `memory_traces.md`) will always remain at the top level

The gold is safe.  
The recursion is stable.  
The plan scales with you.

---
